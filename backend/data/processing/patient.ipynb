{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define a cleaning function for each name\n",
    "def clean_name(name):\n",
    "    # Check for null values\n",
    "    if pd.isnull(name):\n",
    "        return None\n",
    "\n",
    "    # Titles to remove (in lowercase)\n",
    "    titles = {\"mr\", \"mrs\", \"smt\", \"shri\", \"mas\", \"miss\", \"ms\"}\n",
    "\n",
    "    # Split the name into words\n",
    "    words = name.split()\n",
    "    cleaned_words = []\n",
    "\n",
    "    for word in words:\n",
    "        # Remove surrounding punctuation for title checking\n",
    "        word_stripped = re.sub(r'^[^\\w]+|[^\\w]+$', '', word)\n",
    "        \n",
    "        # If the stripped word is a title, skip it.\n",
    "        if word_stripped.lower() in titles:\n",
    "            continue\n",
    "        \n",
    "        # Remove the word if it contains any numbers\n",
    "        if re.search(r'\\d', word_stripped):\n",
    "            continue\n",
    "        \n",
    "        # Remove the word if it contains any symbols (only allow letters)\n",
    "        # Note: word_stripped.isalpha() returns True only if all characters are alphabetic.\n",
    "        if not word_stripped.isalpha():\n",
    "            continue\n",
    "\n",
    "        # If the word passes all filters, add it\n",
    "        cleaned_words.append(word_stripped)\n",
    "\n",
    "    # If no valid words remain, return None\n",
    "    if not cleaned_words:\n",
    "        return None\n",
    "\n",
    "    # Rejoin the cleaned words into a single string\n",
    "    cleaned_name = \" \".join(cleaned_words)\n",
    "\n",
    "    # Remove the row if the cleaned name doesn't contain any alphabets\n",
    "    if not re.search(r'[A-Za-z]', cleaned_name):\n",
    "        return None\n",
    "\n",
    "    # Capitalize only the first word (the rest remain as they are)\n",
    "    cleaned_name = \" \".join(word.capitalize() for word in cleaned_words)\n",
    "\n",
    "    return cleaned_name\n",
    "\n",
    "# Example: Cleaning the 'name' column in a DataFrame\n",
    "# For instance, for Indian Males:\n",
    "df_males = pd.read_csv('indian_males.csv')\n",
    "\n",
    "# Apply the cleaning function\n",
    "df_males['name'] = df_males['name'].apply(clean_name)\n",
    "\n",
    "# Drop rows where the name is None (either originally null or became invalid after cleaning)\n",
    "df_males.dropna(subset=['name'], inplace=True)\n",
    "\n",
    "# Similarly, for Indian Females:\n",
    "df_females = pd.read_csv('indian_females.csv')\n",
    "df_females['name'] = df_females['name'].apply(clean_name)\n",
    "df_females.dropna(subset=['name'], inplace=True)\n",
    "\n",
    "# Combine both datasets\n",
    "df_combined = pd.concat([df_males, df_females], ignore_index=True)\n",
    "\n",
    "# Randomize (shuffle) the combined DataFrame\n",
    "df_combined = df_combined.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned data if needed\n",
    "df_combined.to_csv('cleaned_names.csv', index=False)\n",
    "\n",
    "print(\"Cleaning complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\PRAMOD\n",
      "[nltk_data]     PANT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# Download the english words corpus if not already available.\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words as nltk_words\n",
    "\n",
    "# Create a set of English words (all lowercased)\n",
    "english_vocab = set(word.lower() for word in nltk_words.words())\n",
    "\n",
    "def has_english_word(name):\n",
    "    \"\"\"Return True if any word in the name is found in the English vocabulary.\"\"\"\n",
    "    for word in name.split():\n",
    "        if word.lower() in english_vocab:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_repeated_words(name):\n",
    "    \"\"\"Return True if the name contains repeated words.\"\"\"\n",
    "    words_in_name = name.split()\n",
    "    return len(words_in_name) != len(set(words_in_name))\n",
    "\n",
    "def generate_username(name, existing_usernames):\n",
    "    \"\"\"\n",
    "    Generate a unique username inspired by the name.\n",
    "    The base username is the name with spaces removed and lowercased.\n",
    "    If the username already exists, append a counter until it is unique.\n",
    "    \"\"\"\n",
    "    base = ''.join(name.split()).lower()\n",
    "    username = base\n",
    "    counter = 1\n",
    "    while username in existing_usernames:\n",
    "        username = f\"{base}{counter}\"\n",
    "        counter += 1\n",
    "    existing_usernames.add(username)\n",
    "    return username\n",
    "\n",
    "def generate_password(length=8):\n",
    "    \"\"\"\n",
    "    Generate a random password of the given length using alphanumeric characters\n",
    "    and punctuation symbols.\n",
    "    \"\"\"\n",
    "    characters = string.ascii_letters + string.digits + string.punctuation\n",
    "    return ''.join(random.choices(characters, k=length))\n",
    "\n",
    "# ---------------------------\n",
    "# Assume we start with the cleaned names DataFrame.\n",
    "# For example, load from a CSV file:\n",
    "df_cleaned = pd.read_csv('cleaned_names.csv')\n",
    "\n",
    "# 1. Drop the 'race' column if it exists.\n",
    "if 'race' in df_cleaned.columns:\n",
    "    df_cleaned = df_cleaned.drop(columns=['race'])\n",
    "\n",
    "# 2. Remove rows where the Name contains the word 'and' (case-insensitive, as a whole word).\n",
    "df_cleaned = df_cleaned[~df_cleaned['name'].str.contains(r'\\band\\b', flags=re.IGNORECASE, regex=True)]\n",
    "\n",
    "# 3. Remove names that contain any English words or have repeated words.\n",
    "def name_filter(name):\n",
    "    if has_english_word(name):\n",
    "        return False\n",
    "    if has_repeated_words(name):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df_cleaned = df_cleaned[df_cleaned['name'].apply(name_filter)]\n",
    "\n",
    "# 4. Generate unique usernames inspired by the names.\n",
    "existing_usernames = set()\n",
    "df_cleaned['username'] = df_cleaned['name'].apply(lambda name: generate_username(name, existing_usernames))\n",
    "\n",
    "# 5. Generate a random 8-character password for each row.\n",
    "df_cleaned['password'] = [generate_password() for _ in range(len(df_cleaned))]\n",
    "\n",
    "# (Optional) Save the final DataFrame to a new CSV file.\n",
    "df_cleaned.to_csv('final_cleaned_names.csv', index=False)\n",
    "\n",
    "print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      patient_id           name gender      username  password\n",
      "0        P001AAA  Sujata Dhawan      f  sujatadhawan  ^-/'~`=!\n",
      "1        P002AAA    Jai Bhagwan      m    jaibhagwan  S<*iV+&n\n",
      "2        P003AAA      Bhagwanti      f     bhagwanti  5hCi?.{q\n",
      "3        P004AAA   Kushal Gupta      m   kushalgupta  k}?%&O^@\n",
      "4        P005AAA   Gaurav Kumar      m   gauravkumar  MIwv~:@k\n",
      "...          ...            ...    ...           ...       ...\n",
      "22728    P729AAW     Km Sivhani      f     kmsivhani  S3Z#?1\"?\n",
      "22729    P730AAW         Mukesh      m      mukesh50  ^j[Uot^2\n",
      "22730    P731AAW   Parnav Kumar      m  parnavkumar1  <>c+Vw|k\n",
      "22731    P732AAW     Amit Kumar      m   amitkumar53  \\)=X1Lp3\n",
      "22732    P733AAW    Ladu Kunwar      f    ladukunwar  bdd{,$3c\n",
      "\n",
      "[22733 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Patient ID Generator Functions ---\n",
    "\n",
    "def increment_letters(letters):\n",
    "    \"\"\"\n",
    "    Increment the three-letter list as a base-26 number.\n",
    "    Only the last letter is incremented on each rollover.\n",
    "    If a letter is 'Z', it resets to 'A' and the next letter to its left is incremented.\n",
    "    \"\"\"\n",
    "    i = len(letters) - 1\n",
    "    while i >= 0:\n",
    "        if letters[i] != 'Z':\n",
    "            letters[i] = chr(ord(letters[i]) + 1)\n",
    "            break\n",
    "        else:\n",
    "            letters[i] = 'A'\n",
    "            i -= 1\n",
    "    return letters\n",
    "\n",
    "def patient_id_generator():\n",
    "    \"\"\"\n",
    "    Yields patient IDs with the following format:\n",
    "    - Starts at P001AAA\n",
    "    - Increments the numeric part first (001 -> 999)\n",
    "    - When numeric part hits 999, the next id resets the number to 000 and increments the letter part.\n",
    "    \"\"\"\n",
    "    num = 1\n",
    "    letters = list(\"AAA\")  # start with AAA\n",
    "    while True:\n",
    "        # Generate current patient id\n",
    "        pid = f\"P{num:03d}{''.join(letters)}\"\n",
    "        yield pid\n",
    "        \n",
    "        # Increment numeric part; if it rolls over, reset and increment letters.\n",
    "        if num == 999:\n",
    "            num = 0\n",
    "            letters = increment_letters(letters)\n",
    "        else:\n",
    "            num += 1\n",
    "\n",
    "# --- Example: Adding Patient IDs to Your DataFrame ---\n",
    "\n",
    "# Suppose df_cleaned is your DataFrame after previous cleaning steps.\n",
    "# For demonstration, let's create a sample DataFrame:\n",
    "df_cleaned = pd.read_csv(\"final_cleaned_names.csv\")\n",
    "\n",
    "# Create an instance of the patient id generator\n",
    "id_gen = patient_id_generator()\n",
    "\n",
    "# Generate and insert a patient_id column as the first column in the DataFrame.\n",
    "df_cleaned.insert(0, 'patient_id', [next(id_gen) for _ in range(len(df_cleaned))])\n",
    "\n",
    "# Display the DataFrame with the new patient_id column\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_excel(\"patient_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine  \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\PRAMOD PANT\\\\Desktop\\\\EPICS\\\\Review 2\\\\final_cleaned_dataset.xlsx\")\n",
    "# PostgreSQL connection string  \n",
    "engine = create_engine(\"postgresql://postgres:Archit@localhost/epics\")  \n",
    "\n",
    "# Load and save to PostgreSQL  \n",
    "df.to_sql(\"doctors\", engine, if_exists=\"replace\", index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
